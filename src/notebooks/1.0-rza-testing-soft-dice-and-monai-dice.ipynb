{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import Dice\n",
    "from torchmetrics.functional import dice\n",
    "from monai.losses import DiceLoss, MaskedDiceLoss\n",
    "from monai.metrics import GeneralizedDiceScore, DiceMetric\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "file = Path(current_dir).resolve()\n",
    "sys.path.append(str(file.parents[0]))\n",
    "sys.path.append(str(file.parents[1]))\n",
    "#sys.path.append(str(file.parents[2]))\n",
    "\n",
    "from utils.dice import MemoryEfficientSoftDiceLoss\n",
    "from utils.dice_loss import SoftDiceLoss\n",
    "#import utils.dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc_loss_w = 1.0\n",
    "\n",
    "#Torchmetrics\n",
    "#Dice = torchmetrics.Dice(average='macro', num_classes=4)\n",
    "DiceScore = Dice()\n",
    "DiceFGScore = Dice(ignore_index=0) #ignore_index=0 means we ignore the background class\n",
    "\n",
    "#MONAI Losses and Scores\n",
    "MonaiDiceLoss = DiceLoss()\n",
    "MonaiDiceLogitLoss = DiceLoss(softmax=True, to_onehot_y=True)\n",
    "MonaiMaskedDiceLoss = MaskedDiceLoss(softmax = True, to_onehot_y=True)\n",
    "\n",
    "MonaiDiceScore = GeneralizedDiceScore()\n",
    "MonaiDiceFGScore = GeneralizedDiceScore(include_background=False)\n",
    "MonaiDiceMetric = DiceMetric(ignore_empty=False)\n",
    "MonaiDiceMetricFG = DiceMetric(include_background=False, ignore_empty=False)\n",
    "\n",
    "# Memory Efficient Soft Dice Loss\n",
    "MESoftDiceLogitLoss = MemoryEfficientSoftDiceLoss(nn.Softmax(dim = 1), do_bg=True, smooth = 1e-5)\n",
    "MESoftDiceLoss = MemoryEfficientSoftDiceLoss(do_bg=True, smooth = 1e-5)\n",
    "MESoftDiceLossFG = MemoryEfficientSoftDiceLoss(do_bg=False, smooth = 1e-5)\n",
    "\n",
    "#Soft Dice Loss\n",
    "SoftDiceLogitLoss = SoftDiceLoss(nn.Softmax(dim = 1), do_bg=True, smooth = 1e-5)\n",
    "SoftDiceL = SoftDiceLoss(smooth = 1e-5)\n",
    "\n",
    "\n",
    "Softmax = nn.Softmax(dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Tensors 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: tensor([[0, 1, 1],\n",
      "        [1, 2, 0],\n",
      "        [1, 2, 0]])\n",
      "Ground Truth: tensor([[1, 2, 3],\n",
      "        [0, 1, 1],\n",
      "        [0, 0, 1]])\n",
      "logits shape torch.Size([1, 4, 3, 3])\n",
      "Probs Shape:  torch.Size([1, 4, 3, 3])\n",
      "Preds Shape:  torch.Size([1, 1, 3, 3])\n",
      "Masks Shape:  torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Creating Dummy Test Tensors for testing of same format as in the model [B, C, H, W, D]\n",
    "# B = Batch Size, C = Number of Classes, H = Height, W = Width, D = Depth\n",
    "# Example with Batch Size 1, 4 Classes, Height 3, Width 3, Depth 3\n",
    "n_classes = 4\n",
    "og_probs = torch.tensor(\n",
    "    [[[0.7, 0.1, 0.1],  # Class 0 (corresponding to preds == 0)\n",
    "     [0.1, 0.05, 0.6],\n",
    "     [0.1, 0.05, 0.6]],\n",
    "\n",
    "    [[0.2, 0.6, 0.6],  # Class 1 (corresponding to preds == 1)\n",
    "     [0.6, 0.1, 0.2],\n",
    "     [0.6, 0.1, 0.2]],\n",
    "\n",
    "    [[0.05, 0.2, 0.2],  # Class 2 (corresponding to preds == 2)\n",
    "     [0.2, 0.7, 0.1],\n",
    "     [0.2, 0.7, 0.1]],\n",
    "\n",
    "    [[0.05, 0.1, 0.1],  # Class 3 (no predictions, so probabilities are lower)\n",
    "     [0.1, 0.15, 0.1],\n",
    "     [0.1, 0.15, 0.1]]]\n",
    ")\n",
    "\n",
    "logits = torch.log(og_probs / (1 - og_probs))\n",
    "\n",
    "probs = Softmax(logits)\n",
    "\n",
    "preds = torch.argmax(probs, dim=0)\n",
    "masks = torch.tensor([[1, 2, 3], [0, 1, 1], [0, 0, 1]])\n",
    "\n",
    "print(f\"Preds: {preds}\")\n",
    "print(f\"Ground Truth: {masks}\")\n",
    "\n",
    "# Uniform shape of B, C, H, W\n",
    "logits.unsqueeze_(0)\n",
    "probs.unsqueeze_(0)\n",
    "preds.unsqueeze_(0).unsqueeze_(0) \n",
    "masks.unsqueeze_(0).unsqueeze_(0)\n",
    "\n",
    "print(f\"logits shape {logits.shape}\")\n",
    "print(\"Probs Shape: \", probs.shape)\n",
    "print(\"Preds Shape: \", preds.shape)\n",
    "print(\"Masks Shape: \", masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds_oh.shape: torch.Size([1, 4, 3, 3])\n",
      "masks_oh.shape: torch.Size([1, 4, 3, 3])\n",
      "probs.shape: torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding, permuting and unsqueezing to match the format BNHW[D], where B = Batch Size, N = Number of Classes, H = Height, W = Width, D = Depth\n",
    "preds_oh = torch.nn.functional.one_hot(preds.squeeze(1), n_classes).permute(0, 3, 1, 2)\n",
    "masks_oh = torch.nn.functional.one_hot(masks.squeeze(1), n_classes).permute(0, 3, 1, 2)\n",
    "\n",
    "if probs.dim() == 3:\n",
    "    probs.unsqueeze_(0)\n",
    "\n",
    "print(f\"preds_oh.shape: {preds_oh.shape}\")\n",
    "print(f\"masks_oh.shape: {masks_oh.shape}\")\n",
    "print(f\"probs.shape: {probs.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Tensors 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits Shape: torch.Size([1, 4, 3, 3])\n",
      "Probs Shape:  torch.Size([1, 4, 3, 3])\n",
      "Preds Shape:  torch.Size([1, 1, 3, 3])\n",
      "Masks Shape:  torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Testing with example tensors from terminal\n",
    "# unique values in masks: [0 2 3]\n",
    "# unique values in preds: [0 2]\n",
    "n_classes = 4\n",
    "\n",
    "og_probs = torch.tensor(\n",
    "[\n",
    "    # Class 0 probabilities (corresponding to preds == 0)\n",
    "    [[0.7, 0.8, 0.1],   # Class 0 has highest probability for preds == 0\n",
    "     [0.1, 0.1, 0.1],  \n",
    "     [0.8, 0.1, 0.7]],\n",
    "\n",
    "    # Class 1 probabilities\n",
    "    [[0.1, 0.1, 0.1],   # Class 1 does not have the highest probability anywhere\n",
    "     [0.1, 0.1, 0.1],  \n",
    "     [0.05, 0.05, 0.1]],\n",
    "\n",
    "    # Class 2 probabilities (corresponding to preds == 2)\n",
    "    [[0.1, 0.05, 0.75],  # Class 2 has highest probability for preds == 2\n",
    "     [0.75, 0.8, 0.1],  \n",
    "     [0.1, 0.75, 0.1]],\n",
    "\n",
    "    # Class 3 probabilities (corresponding to preds == 3)\n",
    "    [[0.1, 0.05, 0.05],  # Class 3 has highest probability where preds == 3\n",
    "     [0.05, 0.05, 0.7],  \n",
    "     [0.05, 0.1, 0.1]]\n",
    "]\n",
    ")\n",
    "\n",
    "logits = torch.log(og_probs / (1 - og_probs))\n",
    "\n",
    "probs = Softmax(logits)\n",
    "\n",
    "preds = torch.argmax(probs, dim=0)\n",
    "masks = torch.tensor([[0, 0, 2], [2, 2, 0], [0, 2, 2]])\n",
    "\n",
    "# Uniform shape of B, C, H, W\n",
    "logits.unsqueeze_(0)\n",
    "probs.unsqueeze_(0)\n",
    "preds.unsqueeze_(0).unsqueeze_(0) \n",
    "masks.unsqueeze_(0).unsqueeze_(0)\n",
    "\n",
    "print(f\"logits Shape: {logits.shape}\")\n",
    "print(\"Probs Shape: \", probs.shape)\n",
    "print(\"Preds Shape: \", preds.shape)\n",
    "print(\"Masks Shape: \", masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0, 0, 2],\n",
      "          [2, 2, 3],\n",
      "          [0, 2, 0]]]])\n",
      "tensor([[[[0, 0, 2],\n",
      "          [2, 2, 0],\n",
      "          [0, 2, 2]]]])\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds_oh.shape: torch.Size([1, 4, 3, 3])\n",
      "masks_oh.shape: torch.Size([1, 4, 3, 3])\n",
      "probs.shape: torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding, permuting and unsqueezing to match the format BNHW[D], where B = Batch Size, N = Number of Classes, H = Height, W = Width, D = Depth\n",
    "preds_oh = torch.nn.functional.one_hot(preds.squeeze(1), n_classes).permute(0, 3, 1, 2)\n",
    "masks_oh = torch.nn.functional.one_hot(masks.squeeze(1), n_classes).permute(0, 3, 1, 2)\n",
    "\n",
    "if probs.dim() == 3:\n",
    "    probs.unsqueeze_(0)\n",
    "\n",
    "print(f\"preds_oh.shape: {preds_oh.shape}\")\n",
    "print(f\"masks_oh.shape: {masks_oh.shape}\")\n",
    "print(f\"probs.shape: {probs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Tensor 3 (Background heavy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: tensor([[0, 0, 0],\n",
      "        [3, 2, 0],\n",
      "        [0, 1, 0]])\n",
      "ground truth: tensor([[0, 0, 0],\n",
      "        [0, 2, 3],\n",
      "        [0, 1, 0]])\n",
      "\n",
      "logits Shape: torch.Size([4, 3, 3])\n",
      "Probs Shape:  torch.Size([4, 3, 3])\n",
      "Preds Shape:  torch.Size([3, 3])\n",
      "Masks Shape:  torch.Size([3, 3])\n",
      "\n",
      "Shape transformation to Torch Lightning Format\n",
      "\n",
      "logits Shape: torch.Size([1, 4, 3, 3])\n",
      "Probs Shape:  torch.Size([1, 4, 3, 3])\n",
      "Preds Shape:  torch.Size([1, 1, 3, 3])\n",
      "Masks Shape:  torch.Size([1, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "\n",
    "og_probs = torch.tensor(\n",
    "[\n",
    "    # Class 0 probabilities (background)\n",
    "    [[0.9, 0.9, 0.9],  # Class 0 dominates where ground truth is 0\n",
    "     [0.1, 0.1, 0.9],\n",
    "     [0.9, 0.1, 0.9]],\n",
    "\n",
    "    # Class 1 probabilities\n",
    "    [[0.05, 0.05, 0.05],   # Low probability for Class 1 where it's not the ground truth\n",
    "     [0.05, 0.05, 0.05],\n",
    "     [0.05, 0.8, 0.05]],   # Higher probability for Class 1 at (2, 1)\n",
    "\n",
    "    # Class 2 probabilities\n",
    "    [[0.05, 0.05, 0.05],   # Low probability for Class 2 where it's not the ground truth\n",
    "     [0.1, 0.8, 0.05],     # Higher probability for Class 2 at (1, 1)\n",
    "     [0.05, 0.05, 0.05]],\n",
    "\n",
    "    # Class 3 probabilities\n",
    "    [[0.05, 0.05, 0.05],   # Low probability for Class 3 where it's not the ground truth\n",
    "     [0.8, 0.05, 0.05],    # Higher probability for Class 3 at (1, 0)\n",
    "     [0.05, 0.05, 0.05]]\n",
    "]\n",
    ")\n",
    "\n",
    "logits = torch.log(og_probs / (1 - og_probs))\n",
    "\n",
    "probs = Softmax(logits)\n",
    "\n",
    "preds = torch.argmax(probs, dim=0)\n",
    "masks = torch.tensor([[0, 0, 0 ], [0, 2, 3], [0, 1, 0]])\n",
    "\n",
    "print(f\"preds: {preds}\")\n",
    "print(f\"ground truth: {masks}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"logits Shape: {logits.shape}\")\n",
    "print(\"Probs Shape: \", probs.shape)\n",
    "print(\"Preds Shape: \", preds.shape)\n",
    "print(\"Masks Shape: \", masks.shape)\n",
    "\n",
    "print()\n",
    "print(f\"Shape transformation to Torch Lightning Format\")\n",
    "print()\n",
    "\n",
    "# Uniform shape of B, C, H, W\n",
    "logits.unsqueeze_(0)\n",
    "probs.unsqueeze_(0)\n",
    "preds.unsqueeze_(0).unsqueeze_(0) \n",
    "masks.unsqueeze_(0).unsqueeze_(0)\n",
    "\n",
    "print(f\"logits Shape: {logits.shape}\")\n",
    "print(\"Probs Shape: \", probs.shape)\n",
    "print(\"Preds Shape: \", preds.shape)\n",
    "print(\"Masks Shape: \", masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.1972,  2.1972,  2.1972],\n",
      "          [-2.1972, -2.1972,  2.1972],\n",
      "          [ 2.1972, -2.1972,  2.1972]],\n",
      "\n",
      "         [[-2.9444, -2.9444, -2.9444],\n",
      "          [-2.9444, -2.9444, -2.9444],\n",
      "          [-2.9444,  1.3863, -2.9444]],\n",
      "\n",
      "         [[-2.9444, -2.9444, -2.9444],\n",
      "          [-2.1972,  1.3863, -2.9444],\n",
      "          [-2.9444, -2.9444, -2.9444]],\n",
      "\n",
      "         [[-2.9444, -2.9444, -2.9444],\n",
      "          [ 1.3863, -2.9444, -2.9444],\n",
      "          [-2.9444, -2.9444, -2.9444]]]])\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds_oh.shape: torch.Size([1, 4, 3, 3])\n",
      "masks_oh.shape: torch.Size([1, 4, 3, 3])\n",
      "probs.shape: torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding, permuting and unsqueezing to match the format BNHW[D], where B = Batch Size, N = Number of Classes, H = Height, W = Width, D = Depth\n",
    "preds_oh = torch.nn.functional.one_hot(preds.squeeze(1), n_classes).permute(0, 3, 1, 2)\n",
    "masks_oh = torch.nn.functional.one_hot(masks.squeeze(1), n_classes).permute(0, 3, 1, 2)\n",
    "\n",
    "if probs.dim() == 3:\n",
    "    probs.unsqueeze_(0)\n",
    "\n",
    "print(f\"preds_oh.shape: {preds_oh.shape}\")\n",
    "print(f\"masks_oh.shape: {masks_oh.shape}\")\n",
    "print(f\"probs.shape: {probs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Calculation of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7500,    nan, 0.8889, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "dice_p_cls = dice(logits, masks, average=None, num_classes=n_classes) # average=None returns dice per class\n",
    "print(dice_p_cls)\n",
    "\n",
    "# -> dice for class 1 should be 1 as predictions didn't contain the class which was also absent in the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchmetrics Dice Scores\n",
      "dsc: 0.7777777910232544\n",
      "dsc w logits 0.7777777910232544\n",
      "dsc w probs 0.7777777910232544\n"
     ]
    }
   ],
   "source": [
    "# Dice Scores:\n",
    "dsc = dice(preds, masks)\n",
    "dscwlogits = dice(logits, masks)\n",
    "dscwprobs = dice(probs, masks)\n",
    "\n",
    "print(f\"Torchmetrics Dice Scores\")\n",
    "print(f\"dsc: {dsc}\")\n",
    "print(f\"dsc w logits {dscwlogits}\")\n",
    "print(f\"dsc w probs {dscwprobs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Score FG:  tensor(0.8000)\n",
      "Dice Score per Class:  tensor([0.7500,    nan, 0.8889, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "diceFG = dice(preds, masks, ignore_index=0)\n",
    "dice_p_cls = dice(preds, masks, average=None, num_classes=n_classes) # average=None returns dice per class\n",
    "\n",
    "print(\"Dice Score FG: \", diceFG)\n",
    "print(\"Dice Score per Class: \", dice_p_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monai Generalized Dice Score\n",
      "Monai Dice Score: tensor([0.7534])\n",
      "Monai Dice FG Score tensor([0.8000])\n",
      "Monai Dice Metric: tensor([[0.7500, 1.0000, 0.8889, 0.0000]])\n",
      "Monai Dice Metric FG: tensor([[1.0000, 0.8889, 0.0000]])\n",
      "Monai Dice Metric Mean: 0.6597222089767456\n",
      "Monai Dice Metric FG Mean: 0.6296296119689941\n"
     ]
    }
   ],
   "source": [
    "# Monai Dice Score\n",
    "monaidicescore = MonaiDiceScore(preds_oh, masks_oh)\n",
    "monaidicescoreFG = MonaiDiceFGScore(preds_oh, masks_oh)\n",
    "\n",
    "monaidicemetric = MonaiDiceMetric(preds_oh, masks_oh)\n",
    "monaidicemetricFG = MonaiDiceMetricFG(preds_oh, masks_oh)\n",
    "\n",
    "\n",
    "print(f\"Monai Generalized Dice Score\")\n",
    "print(f\"Monai Dice Score: {monaidicescore}\")\n",
    "print(f\"Monai Dice FG Score {monaidicescoreFG}\")\n",
    "print(f\"Monai Dice Metric: {monaidicemetric}\")\n",
    "print(f\"Monai Dice Metric FG: {monaidicemetricFG}\")\n",
    "print(f\"Monai Dice Metric Mean: {monaidicemetric.mean()}\")\n",
    "print(f\"Monai Dice Metric FG Mean: {monaidicemetricFG.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME Soft Dice Score w Probs: 0.39053675532341003\n",
      "ME Soft Dice Score w Logits 0.39053675532341003\n",
      "Soft Dice Score w Logits: 0.39054885506629944\n",
      "ME soft dice score FG 0.2807177007198334\n"
     ]
    }
   ],
   "source": [
    "# Soft Dice Scores\n",
    "\n",
    "mesoftdicescore = MESoftDiceLoss(probs, masks)\n",
    "mesoftdicelogitscore = MESoftDiceLogitLoss(logits, masks)\n",
    "softdicescore = -SoftDiceLogitLoss(logits, masks)\n",
    "mesoftdicescorefg = MESoftDiceLossFG(probs, masks)\n",
    "\n",
    "print(f\"ME Soft Dice Score w Probs: {mesoftdicescore}\")\n",
    "print(f\"ME Soft Dice Score w Logits {mesoftdicelogitscore}\")\n",
    "print(f\"Soft Dice Score w Logits: {softdicescore}\")\n",
    "print(f\"ME soft dice score FG {mesoftdicescorefg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.2000e-01, 3.6528e-05, 8.4215e-01, 9.4189e-06])\n",
      "tensor(0.3905)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the intersection and union for Soft Dice Score\n",
    "def soft_dice_score(probabilities, one_hot_masks, smooth=1e-5):\n",
    "    num_classes = probabilities.size(1)\n",
    "\n",
    "    intersection = (probabilities * one_hot_masks).sum(dim=(0, 2, 3))\n",
    "    union = probabilities.sum(dim=(0, 2, 3)) + one_hot_masks.sum(dim=(0, 2, 3))\n",
    "\n",
    "    dice_score = (2 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return dice_score\n",
    "\n",
    "# Calculate the Soft Dice Score\n",
    "soft_dice = soft_dice_score(probs, masks_oh)\n",
    "print(soft_dice)\n",
    "print(soft_dice.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BraTs Region Scores:\n",
      "Dice Score ET:  tensor(0.8889)\n",
      "Dice FG Score ET:  tensor(0.)\n",
      "Dice Score TC:  tensor(0.8889)\n",
      "Dice FG Score TC:  tensor(0.)\n",
      "Dice Score WT:  tensor(0.7778)\n",
      "Dice FG Score WT:  tensor(0.8000)\n"
     ]
    }
   ],
   "source": [
    "# ET (Enhancing Tumor): label 3\n",
    "dice_ET = DiceScore((preds == 3), (masks == 3))\n",
    "dice_FG_ET = DiceFGScore((preds == 3), (masks == 3))\n",
    "\n",
    "# TC(Tumor Core): ET + NCR = label 1 + label 3\n",
    "dice_TC = DiceScore((preds == 1) | (preds == 3), (masks == 1) | (masks == 3))\n",
    "dice_FG_TC = DiceFGScore((preds == 1) | (preds == 3), (masks == 1) | (masks == 3))\n",
    "\n",
    "# WT (Whole Tumor): TC + ED = label 1 + label 2 + label 3\n",
    "dice_WT = DiceScore((preds > 0), (masks > 0))\n",
    "dice_FG_WT = DiceFGScore((preds > 0), (masks > 0))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"BraTs Region Scores:\")\n",
    "print(\"Dice Score ET: \", dice_ET)\n",
    "print(\"Dice FG Score ET: \", dice_FG_ET)\n",
    "print(\"Dice Score TC: \", dice_TC)\n",
    "print(\"Dice FG Score TC: \", dice_FG_TC)\n",
    "print(\"Dice Score WT: \", dice_WT)\n",
    "print(\"Dice FG Score WT: \", dice_FG_WT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Score with One-Hot Encoded Predictions and Masks:\n",
      "Dice with oh preds: 0.8888888955116272\n",
      "DiceFG with oh preds: 0.7777777910232544\n"
     ]
    }
   ],
   "source": [
    "#Using One-Hot Encoded Predictions and Masks\n",
    "print(f\"Dice Score with One-Hot Encoded Predictions and Masks:\")\n",
    "print(f\"Dice with oh preds: {DiceScore(preds_oh, masks_oh)}\")\n",
    "print(f\"DiceFG with oh preds: {DiceFGScore(preds_oh, masks_oh)}\")\n",
    "\n",
    "# Use DiceFG when using one-hot encoding and non-binary case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft dice logit loss 0.609451174736023\n",
      "soft dice loss 0.609451174736023\n",
      "\n",
      "ME soft dice logit loss 0.6094632148742676\n",
      "ME soft dice loss 0.6094632148742676\n",
      "\n",
      "Custom soft dice: 0.609451174736023\n"
     ]
    }
   ],
   "source": [
    "# Soft Dice Losses\n",
    "mesoftdicelogitloss = 1 - MESoftDiceLogitLoss(logits, masks)\n",
    "mesoftdiceloss = 1 - MESoftDiceLoss(probs, masks) \n",
    "\n",
    "softdicelogitloss = 1 + SoftDiceLogitLoss(logits, masks)\n",
    "softdiceloss = 1 + SoftDiceL(probs, masks)\n",
    "\n",
    "print(f\"soft dice logit loss {softdicelogitloss}\")\n",
    "print(f\"soft dice loss {softdiceloss}\")\n",
    "print()\n",
    "print(f\"ME soft dice logit loss {mesoftdicelogitloss}\")\n",
    "print(f\"ME soft dice loss {mesoftdiceloss}\")\n",
    "print()\n",
    "print(f\"Custom soft dice: {1- soft_dice_score(probs, masks_oh).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dice loss w torchmetrics 0.2222222089767456\n",
      " monai dice loss:  0.609451174736023\n"
     ]
    }
   ],
   "source": [
    "# Hard Losses\n",
    "diceloss = 1- DiceScore(logits, masks)\n",
    "MonaiDiceLogitLoss = DiceLoss(softmax = True, to_onehot_y=True)\n",
    "monaidiceloss = MonaiDiceLogitLoss(logits, masks)\n",
    "\n",
    "print(f\" dice loss w torchmetrics {diceloss}\")\n",
    "print(f\" monai dice loss:  {monaidiceloss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brats Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "brats_regions = {'ET': [3], 'TC': [1, 3], 'WT': [1, 2, 3]}\n",
    "\n",
    "def prepare_region_logits(logits, target_classes):\n",
    "    \"\"\"\n",
    "    Efficiently sum the logits for the given target classes.\n",
    "    \"\"\"\n",
    "    return logits[:, target_classes].sum(dim=1, keepdim=True)\n",
    "\n",
    "def prepare_region_gt(gt, target_classes):\n",
    "    \"\"\"\n",
    "    Efficiently create a binary mask for the relevant target classes.\n",
    "    \"\"\"\n",
    "    return torch.isin(gt, torch.tensor(target_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Approach\n",
      "Dice ET Loss:  tensor(0.1111)\n",
      "Dice ET FG Loss: 1.0\n",
      "Dice TC Loss:  tensor(0.1111)\n",
      "Dice TC FG Loss: 1.0\n",
      "Dice WT Loss:  tensor(0.2222)\n",
      "Dice WT FG Loss: 0.19999998807907104\n"
     ]
    }
   ],
   "source": [
    "#Dice Losses\n",
    "# Brats Dice Loss\n",
    "dice_ET_loss = (1 - DiceScore((preds == 3), (masks == 3))) * dsc_loss_w\n",
    "dice_TC_loss = (1 - DiceScore((preds == 1) | (preds == 3), (masks == 1) | (masks == 3)) ) * dsc_loss_w\n",
    "dice_WT_loss = (1 - DiceScore((preds > 0), (masks > 0))) * dsc_loss_w\n",
    "\n",
    "# Brats FG Dice Loss\n",
    "diceFG_ET_loss = (1 - DiceFGScore((preds == 3), (masks == 3))) * dsc_loss_w\n",
    "diceFG_TC_loss = (1 - DiceFGScore((preds == 1) | (preds == 3), (masks == 1) | (masks == 3)) ) * dsc_loss_w\n",
    "diceFG_WT_loss = (1 - DiceFGScore((preds > 0), (masks > 0))) * dsc_loss_w\n",
    "\n",
    "\n",
    "print(f\"Old Approach\")\n",
    "print(\"Dice ET Loss: \", dice_ET_loss)\n",
    "print(f\"Dice ET FG Loss: {diceFG_ET_loss}\")\n",
    "print(\"Dice TC Loss: \", dice_TC_loss)\n",
    "print(f\"Dice TC FG Loss: {diceFG_TC_loss}\")\n",
    "print(\"Dice WT Loss: \", dice_WT_loss)\n",
    "print(f\"Dice WT FG Loss: {diceFG_WT_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Dice Logit Loss ET: 1.1111098956462229e-06\n",
      "Soft Dice Logit Loss TC: 1.1111098956462229e-06\n",
      "Soft Dice Logit Loss WT: 0.7142859101295471\n",
      "\n",
      "ME Soft Dice Logit Loss ET: 0.0\n",
      "ME Soft Dice Logit Loss TC: 0.0\n",
      "ME Soft Dice Logit Loss WT: 0.7142852544784546\n"
     ]
    }
   ],
   "source": [
    "logits_ET = prepare_region_logits(logits, brats_regions['ET'])\n",
    "logits_TC = prepare_region_logits(logits, brats_regions['TC'])\n",
    "logits_WT = prepare_region_logits(logits, brats_regions['WT'])\n",
    "\n",
    "gt_ET = prepare_region_gt(masks, brats_regions['ET'])\n",
    "gt_TC = prepare_region_gt(masks, brats_regions['TC'])\n",
    "gt_WT = prepare_region_gt(masks, brats_regions['WT'])\n",
    "\n",
    "softdicelogitlossET = -SoftDiceLogitLoss(logits_ET, gt_ET)\n",
    "softdicelogitlossTC = -SoftDiceLogitLoss(logits_TC, gt_TC)\n",
    "softdicelogitlossWT = -SoftDiceLogitLoss(logits_WT, gt_WT)\n",
    "\n",
    "mesoftdicelogitlossET = MESoftDiceLogitLoss(logits_ET, gt_ET)\n",
    "mesoftdicelogitlossTC = MESoftDiceLogitLoss(logits_TC, gt_TC)\n",
    "mesoftdicelogitlossWT = MESoftDiceLogitLoss(logits_WT, gt_WT)\n",
    "\n",
    "print(f\"Soft Dice Logit Loss ET: {softdicelogitlossET}\")\n",
    "print(f\"Soft Dice Logit Loss TC: {softdicelogitlossTC}\")\n",
    "print(f\"Soft Dice Logit Loss WT: {softdicelogitlossWT}\")\n",
    "print()\n",
    "print(f\"ME Soft Dice Logit Loss ET: {mesoftdicelogitlossET}\")\n",
    "print(f\"ME Soft Dice Logit Loss TC: {mesoftdicelogitlossTC}\")\n",
    "print(f\"ME Soft Dice Logit Loss WT: {mesoftdicelogitlossWT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Monai Dice Loss ET: 0.8999964594841003\n",
      "Masked Monai Dice Loss TC: 0.8999964594841003\n",
      "Masked Monai Dice Loss WT: 0.7251651883125305\n"
     ]
    }
   ],
   "source": [
    "maskeddicelossET = MonaiMaskedDiceLoss(logits, masks, (masks == 3))\n",
    "maskeddicelossTC = MonaiMaskedDiceLoss(logits, masks, ((masks == 1) | (masks == 3)))\n",
    "maskeddicelossWT = MonaiMaskedDiceLoss(logits, masks, (masks > 0))\n",
    "\n",
    "print (f\"Masked Monai Dice Loss ET: {maskeddicelossET}\")\n",
    "print (f\"Masked Monai Dice Loss TC: {maskeddicelossTC}\")\n",
    "print (f\"Masked Monai Dice Loss WT: {maskeddicelossWT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_mask = (masks == 3).to(torch.uint8)\n",
    "tc_mask = (((masks == 1) | (masks == 3))).to(torch.uint8)\n",
    "wt_mask = ((masks > 0)).to(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ME Soft Dice Logit Loss ET: 0.9000000953674316\n",
      " ME Soft Dice Logit Loss TC: 0.9000000953674316\n",
      " ME Soft Dice Logit Loss WT: 0.7251702547073364\n"
     ]
    }
   ],
   "source": [
    "# Soft Dice Region Loss\n",
    "\n",
    "SoftDiceLogitScore = MemoryEfficientSoftDiceLoss(nn.Softmax(dim=1), smooth= 1e-5)\n",
    "\n",
    "mesoftdicelogitlossET = 1 - SoftDiceLogitScore(logits*et_mask, masks*et_mask)\n",
    "mesoftdicelogitlossTC = 1 - SoftDiceLogitScore(logits*tc_mask, masks*tc_mask)\n",
    "mesoftdicelogitlossWT = 1 - SoftDiceLogitScore(logits*wt_mask, masks*wt_mask)\n",
    "\n",
    "print(f\" ME Soft Dice Logit Loss ET: {mesoftdicelogitlossET}\")\n",
    "print(f\" ME Soft Dice Logit Loss TC: {mesoftdicelogitlossTC}\")\n",
    "print(f\" ME Soft Dice Logit Loss WT: {mesoftdicelogitlossWT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monai Dice Loss\n",
      "Monai Dice Logit Loss ET: 0.8999964594841003\n",
      "Monai Dice Logit Loss TC: 0.8999964594841003\n",
      "Monai Dice Logit Loss WT: 0.7251651883125305\n"
     ]
    }
   ],
   "source": [
    "# Hard Dice Region Loss\n",
    "\n",
    "MonaiDiceLogitLoss = DiceLoss(softmax = True, to_onehot_y=True)\n",
    "\n",
    "monaidicelogitlossET = MonaiDiceLogitLoss(logits*et_mask, masks*et_mask)\n",
    "monaidicelogitlossTC = MonaiDiceLogitLoss(logits*tc_mask, masks*tc_mask)\n",
    "monaidicelogitlossWT = MonaiDiceLogitLoss(logits*wt_mask, masks*wt_mask)\n",
    "\n",
    "print(f\"Monai Dice Loss\")\n",
    "print(f\"Monai Dice Logit Loss ET: {monaidicelogitlossET}\")\n",
    "print(f\"Monai Dice Logit Loss TC: {monaidicelogitlossTC}\")\n",
    "print(f\"Monai Dice Logit Loss WT: {monaidicelogitlossWT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monai Foreground Dice Loss:\n",
      "Monai Dice Logit Loss ET: 0.9999955296516418\n",
      "Monai Dice Logit Loss TC: 0.9999955296516418\n",
      "Monai Dice Logit Loss WT: 0.7446136474609375\n"
     ]
    }
   ],
   "source": [
    "# Hard Dice FG Region Loss\n",
    "\n",
    "MonaiDiceFGLogitLoss = DiceLoss(softmax = True, to_onehot_y=True, include_background=False)\n",
    "\n",
    "monaidicelogitlossFG_ET = MonaiDiceFGLogitLoss(logits*et_mask, masks*et_mask)\n",
    "monaidicelogitlossFG_TC = MonaiDiceFGLogitLoss(logits*tc_mask, masks*tc_mask)\n",
    "monaidicelogitlossFG_WT = MonaiDiceFGLogitLoss(logits*wt_mask, masks*wt_mask)\n",
    "\n",
    "print(f\"Monai Foreground Dice Loss:\")\n",
    "print(f\"Monai Dice Logit Loss ET: {monaidicelogitlossFG_ET}\")\n",
    "print(f\"Monai Dice Logit Loss TC: {monaidicelogitlossFG_TC}\")\n",
    "print(f\"Monai Dice Logit Loss WT: {monaidicelogitlossFG_WT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchmetrics Dice Score:\n",
      " Torchmetrics Dice Logit Score ET: 1.0\n",
      " Torchmetrics Dice Logit Score TC: 1.0\n",
      " Torchmetrics Dice Logit Score WT: 0.8888888955116272\n",
      "\n",
      "Torchmetrics Dice Loss:\n",
      " Torchmetrics Dice Logit Loss ET: 0.0\n",
      " Torchmetrics Dice Logit Loss TC: 0.0\n",
      " Torchmetrics Dice Logit Score WT: 0.1111111044883728\n"
     ]
    }
   ],
   "source": [
    "# Hard Dice Torchmetric Region Loss\n",
    "\n",
    "DiceScore = Dice()\n",
    "\n",
    "dicelogitscoreET = DiceScore(logits*et_mask, masks*et_mask)\n",
    "dicelogitscoreTC = DiceScore(logits*tc_mask, masks*tc_mask)\n",
    "dicelogitscoreWT = DiceScore(logits*wt_mask, masks*wt_mask)\n",
    "\n",
    "print(f\"Torchmetrics Dice Score:\")\n",
    "print(f\" Torchmetrics Dice Logit Score ET: {dicelogitscoreET}\")\n",
    "print(f\" Torchmetrics Dice Logit Score TC: {dicelogitscoreTC}\")\n",
    "print(f\" Torchmetrics Dice Logit Score WT: {dicelogitscoreWT}\")\n",
    "print()\n",
    "print(f\"Torchmetrics Dice Loss:\")\n",
    "print(f\" Torchmetrics Dice Logit Loss ET: {1 -dicelogitscoreET}\")\n",
    "print(f\" Torchmetrics Dice Logit Loss TC: {1 -dicelogitscoreTC}\")\n",
    "print(f\" Torchmetrics Dice Logit Score WT: {1- dicelogitscoreWT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torchmetrics Dice FG Score:\n",
      " Torchmetrics Dice Logit Score ET: 0.0\n",
      " Torchmetrics Dice Logit Score TC: 0.0\n",
      " Torchmetrics Dice Logit Score WT: 0.8888888955116272\n",
      "\n",
      "Torchmetrics Dice FG Loss:\n",
      " Torchmetrics Dice Logit Loss ET: 1.0\n",
      " Torchmetrics Dice Logit Loss TC: 1.0\n",
      " Torchmetrics Dice Logit Loss WT: 0.1111111044883728\n"
     ]
    }
   ],
   "source": [
    "# Hard Dice Torchmetric FG Region Loss\n",
    "\n",
    "DiceFGScore = Dice(ignore_index=0)\n",
    "\n",
    "dicelogitscoreFG_ET = DiceFGScore(logits*et_mask, masks*et_mask)\n",
    "dicelogitscoreFG_TC = DiceFGScore(logits*tc_mask, masks*tc_mask)\n",
    "dicelogitscoreFG_WT = DiceFGScore(logits*wt_mask, masks*wt_mask)\n",
    "\n",
    "print(f\"Torchmetrics Dice FG Score:\")\n",
    "print(f\" Torchmetrics Dice Logit Score ET: {dicelogitscoreFG_ET}\")\n",
    "print(f\" Torchmetrics Dice Logit Score TC: {dicelogitscoreFG_TC}\")\n",
    "print(f\" Torchmetrics Dice Logit Score WT: {dicelogitscoreFG_WT}\")\n",
    "print()\n",
    "print(f\"Torchmetrics Dice FG Loss:\")\n",
    "print(f\" Torchmetrics Dice Logit Loss ET: {1 - dicelogitscoreFG_ET}\")\n",
    "print(f\" Torchmetrics Dice Logit Loss TC: {1 - dicelogitscoreFG_TC}\")\n",
    "print(f\" Torchmetrics Dice Logit Loss WT: {1 - dicelogitscoreFG_WT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
